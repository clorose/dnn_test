from __future__ import print_function

import os, sys, math, copy
import glob
import pandas as pd
import numpy as np

from sklearn.preprocessing import MinMaxScaler, StandardScaler

sys.setrecursionlimit(10000)

import matplotlib.pyplot as plt
import scipy.io as sio

import tensorflow as tf

from keras.models import Model, Sequential

#from keras.engine import Layer, InputSpec
from keras.engine import input_layer, input_spec        #다시 오류 나면 keras 2.1.6설치

from keras.optimizers import RMSprop, SGD, Adam
from keras import initializers, regularizers, constraints
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History
from keras.layers import Dense, Dropout, Activation, Flatten, Input
from keras import backend as K
from keras.utils import np_utils

from function_dataPreprocess import tool_condition, item_inspection, machining_process

#train data
train_sample = pd.read_csv("../data/train.csv", header=0, encoding='utf-8')
path = r'../data/CNC Virtual Data set _v2'
all_files = glob.glob(path +"/*.csv")

#change data type
train_sample_np = np.array(train_sample.copy())     #첫행의 컬럼명 사라짐

'''
#결과 데이터 개수 확인
nb_pass = 0
nb_pass_half = 0
nb_defective = 0

for i in range(len(train_sample_np)):
    if train_sample_np[i,5] == 'no':
        nb_defective += 1
    if train_sample_np[i,5] == 'yes' and train_sample_np[i,6] == 'yes':
        nb_pass += 1
    if train_sample_np[i,5] == 'yes' and train_sample_np[i,6] == 'no':
        nb_pass_half += 1

print('양품 : ', nb_pass)
print('공정완료, 육안검사 불합격 : ', nb_pass_half)
print('공정중지 : ', nb_defective)
print('전체 : ', nb_pass+nb_pass_half+nb_defective)
'''

#load csv file
li_df = []
for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    li_df.append(df)


##학습을 위한 결과라벨 데이터 전처리(train.csv)
#train_sample_info = np.array(train_sample_np.copy())    #copy로 넘겨야?
train_sample_info = tool_condition(train_sample_np)
train_sample_info = item_inspection(train_sample_info)
train_sample_info = np.delete(train_sample_info, 5, 1)
train_sample_info = np.delete(train_sample_info, 0, 1)
train_sample_info = np.delete(train_sample_info, 0, 1)

##학습을 위한 학습 데이터 전처리1(experiment_01~25.csv)
k = 0
li_pass = []
li_pass_half = []
li_fail = []

for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)

    if train_sample_info[k, 3] == 0:
        li_pass.append(df)
    elif train_sample_info[k, 3] == 1:
        li_pass_half.append(df)
    else:
        li_fail.append(df)

    k += 1

#각각 있는 index를 무시하고 병합 (리스트내에 dataframe의 묶음에서 행방향 하나의 데이터프레임으로 병합)
frame01 = pd.concat(li_pass, axis=0, ignore_index=True)
frame02 = pd.concat(li_pass_half, axis=0, ignore_index=True)
frame03 = pd.concat(li_fail, axis=0, ignore_index=True)

data_pass = np.array(frame01.copy())
data_pass_half = np.array(frame02.copy())
data_fail = np.array(frame03.copy())
'''
print('공정완료, 육안 검사 합격 데이터 수 : ', len(data_pass))          #22645
print('공정완료, 육안 검사 불합격 데이터 수 : ', len(data_pass_half))   #6175
print('공정미완료 데이터 수 : ', len(data_fail))                       #3228
'''

data_pass = machining_process(data_pass)
data_pass_half = machining_process(data_pass_half)
data_fail = machining_process(data_fail)
'''
print(data_pass.shape)
print(data_pass_half.shape)
print(data_fail.shape)
'''

##Dataset 구성
data01 = data_pass[0:3228+6175,:]   #미공정+불합격=불량품9403 개수 만큼 양품 개수 설정
data02 = data_pass_half[0:6175,:]
data03 = data_fail[0:3228,:]

data = np.concatenate((data01, data02),axis=0)
data = np.concatenate((data,data03),axis=0)     #X_train    18806   < 학습데이터 - 양품9403+불량품9403
data_all = data_pass[3228+6175:22645,:]         #X_test     13242   < 평가데이터 - 모두 양품

##학습을 위한 학습 데이터 전처리2
sc = MinMaxScaler()
X_train = sc.fit_transform(data)        #normalization
X_train = np.array(X_train)
X_test = sc.fit_transform(data_all)     #normalization < 시험 단계에서 fit을 포함?
X_test = np.array(X_test)

##데이터 라벨링
Y_train = np.zeros((len(X_train),1), dtype='int')   #(18806, 1)
Y_test = np.zeros((len(X_test),1), dtype='int')     #(13242, 1)
l = int(Y_train.shape[0]/2)
Y_train[0:l, :] = 0             #양품
Y_train[l:l*2, :] = 1           #불량품

##학습/검증/평가 데이터 분리
#X_train = 학습90%+검증10% = 16925+1881
#X_test = 평가 = 13242


##AI모델 구축

#AI모델 파라미터 설정
nb_classes = 2      #라벨 종류의 개수 < 현재 데이터에서 '양품', '불량품'으로 2개
batch_size = 1024
epochs = 300
lr = 1e-4

#AI 데이터셋 준비
X_train = X_train.astype('float32')
X_test= X_test.astype('float32')

Y_train = np_utils.to_categorical(Y_train, nb_classes)  #one-hot encoding = [0] [1] > [1. 0.] [0. 1.] : (18806, 1) > (18806, 2)
Y_test= np_utils.to_categorical(Y_test, nb_classes)     #(13242, 1) > (13242, 2)

#AI모델 디자인
model = Sequential()
model.add(Dense(128, activation='relu', input_dim=48))
model.add(Dropout(0.3))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(nb_classes, activation='sigmoid'))
model_checkpoint = ModelCheckpoint('weight_CNC_binary.mat', monitor='val_acc', save_best_only=True)
opt = Adam(lr)
model.summary()
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
history = History()


##AI모델 훈련
model.fit(X_train, Y_train, verbose=2, batch_size=batch_size, epochs=epochs, validation_split=0.1, shuffle=True, callbacks=[history])
model.save_weights('weight_CNC_binary.mat')
model.save("CNC_DLL.h5")


##결과 분석 및 해석
loss_and_metrics = model.evaluate(X_train, Y_train, batch_size=32)
print(loss_and_metrics)

loss_and_metrics2 = model.evaluate(X_test, Y_test, batch_size=32)
print(loss_and_metrics2)


##시각화
plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.savefig('accuracy_plot.png')
plt.show()

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()
plt.savefig('loss_plot.png')
plt.show()

