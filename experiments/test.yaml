# 실험 식별자
tag: optimized_binary_classification

# 분류 설정
classification_type: binary

# 네트워크 구조 설정
hidden_sizes: [256, 512, 1024, 512, 256]  # example의 구조를 참고하되 약간 단순화
dropout_rates: [0.3, 0.3, 0.3, 0.3, 0.3]  # example과 동일한 드롭아웃 비율 유지
use_batch_norm: true  # example은 불안정했으나, 성능이 더 좋았으므로 batch norm 도입

# 학습 설정
batch_size: 1024
epochs: 300
learning_rate: 0.001

# 옵티마이저 설정
optimizer: adam
optimizer_config:
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 1e-07

# 정규화 설정
l2_lambda: 0.01  # 적당한 정규화 유지
label_smoothing: 0.1  # 약간의 라벨 스무딩 도입

# 학습률 스케줄링
use_cosine_scheduler: true  # example의 불안정성을 완화하기 위한 스케줄링
use_reduce_lr: true
reduce_lr_patience: 10
reduce_lr_factor: 0.2
min_lr: 1e-6

# 조기 종료 설정
use_early_stopping: false  # example처럼 충분한 학습 기회 제공
early_stopping_patience: 20

# 모니터링 설정
monitor_metric: "val_loss"