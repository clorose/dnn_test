tag: wide_deep_experiment

# 더 넓고 깊은 네트워크 구조
hidden_sizes: [512, 1024, 2048, 2048, 1024, 512]
dropout_rates: [0.3, 0.3, 0.4, 0.4, 0.3, 0.3]
use_batch_norm: true

# 학습 설정
batch_size: 512  # 더 작은 배치로 더 자주 업데이트
epochs: 300
learning_rate: 0.001

# 옵티마이저 설정
optimizer: adam
optimizer_config:
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 1e-07

# 정규화 설정
l2_lambda: 0.02  # 더 강한 정규화