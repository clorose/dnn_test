# 실험 식별자
tag: adaptive_learning

# 네트워크 구조 설정
hidden_sizes: [256, 512, 1024, 1024, 512, 256]
dropout_rates: [0.3, 0.3, 0.3, 0.3, 0.3, 0.3]
use_batch_norm: true

# 학습 설정
batch_size: 1024
epochs: 300
learning_rate: 0.002  # 초기에 더 높은 학습률

# 옵티마이저 설정
optimizer: adamw     # AdamW로 변경
optimizer_config:
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 1e-07
  weight_decay: 0.01

# 정규화 설정
l2_lambda: 0.01
label_smoothing: 0.1  # 라벨 스무딩 활성화

# 학습률 스케줄링
use_cosine_scheduler: true   # 코사인 스케줄러 활성화
use_reduce_lr: true         # ReduceLROnPlateau 함께 사용
reduce_lr_patience: 15
reduce_lr_factor: 0.2
min_lr: 1e-6

# 조기 종료 설정
use_early_stopping: true
early_stopping_patience: 25

# 모니터링 설정
monitor_metric: "val_loss"